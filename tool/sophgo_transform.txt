Detect
# fuse_preprocess参数指的是将model_transform中的预处理操作融合到模型里，这样在推理代码中就不再需要做归一化了

# YOLOv5
model_transform.py \
    --model_name yolov8s \
    --model_def ./yolov8s-pose_transpose.onnx \
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov8s.mlir


model_deploy.py \
    --mlir yolov8s.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov8s_pose_84x_F16_1b.bmodel

# YOLOv6
model_transform.py \
    --model_name yolov6s \
    --model_def ./yolov6s.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov6s.mlir

 model_deploy.py \
    --mlir yolov6s.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov6s_84x_F16_1b.bmodel

# YOLOv7
model_transform.py \
    --model_name yolov7 \
    --model_def ./yolov7.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov7.mlir

 model_deploy.py \
    --mlir yolov7.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov7_84x_F16_1b.bmodel

# YOLOv8
model_transform.py \
    --model_name yolov8 \
    --model_def ./yolov8s.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov8.mlir

 model_deploy.py \
    --mlir yolov8.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov8_84x_F16_1b.bmodel

# YOLOv9
model_transform.py \
    --model_name yolov9 \
    --model_def ./yolov9-s-converted.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov9.mlir

 model_deploy.py \
    --mlir yolov9.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov9_84x_F16_1b.bmodel

# YOLOv10
model_transform.py \
    --model_name yolov10 \
    --model_def ./yolov10s.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov10.mlir

 model_deploy.py \
    --mlir yolov10.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov10_84x_F16_1b.bmodel

# YOLOv11
model_transform.py \
    --model_name yolov11 \
    --model_def ./yolo11s.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov11.mlir

 model_deploy.py \
    --mlir yolov11.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov11_84x_F16_1b.bmodel

# YOLOv12
model_transform.py \
    --model_name yolov12 \
    --model_def ./yolov12s.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov12.mlir

model_deploy.py \
    --mlir yolov12.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov12_84x_F16_1b.bmodel

---------------------------------------------------------------------
---------------------------------------------------------------------
Segment
# YOLOv5
# ouput_name 参数将模型从指定的位置截断作为输出
model_transform.py \
    --model_name yolov5s \
    --model_def ./yolov5s-seg.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --output_name /model.24/Transpose_output_0,/model.24/Transpose_1_output_0,/model.24/Transpose_2_output_0,output1 \
    --mlir yolov5s.mlir

model_deploy.py \
    --mlir yolov5s.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov5s_seg_84x_F16_1b.bmodel

# YOLOv6
model_transform.py \
    --model_name yolov6s \
    --model_def ./yolov6s_seg.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov6s.mlir

    
model_deploy.py \
    --mlir yolov6s.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov6s_seg_84x_F16_1b.bmodel

# YOLOv8
model_transform.py \
    --model_name yolov8s \
    --model_def ./yolov8s-seg.onnx\
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov8s.mlir

model_deploy.py \
    --mlir yolov8s.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov8s_seg_84x_F16_1b.bmodel

--------------------------------------------------------------
--------------------------------------------------------------
Pose
# YOLOv8
model_transform.py \
    --model_name yolov8s \
    --model_def ./yolov8s-pose_transpose.onnx \
    --input_shapes [[1,3,640,640]] \
    --mean 0.0,0.0,0.0 \
    --scale 0.0039216,0.0039216,0.0039216 \
    --keep_aspect_ratio \
    --pixel_format rgb  \
    --mlir yolov8s.mlir

model_deploy.py \
    --mlir yolov8s.mlir \
    --quantize F16 \
    --chip bm1684x \
    --fuse_preprocess \
    --model yolov8s_pose_84x_F16_1b.bmodel

